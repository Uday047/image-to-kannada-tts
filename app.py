# app.py
import streamlit as st
import time
import numpy as np
import cv2
from PIL import Image
from extract_text import extract_text
from text_to_speech import text_to_speech
import os
import base64

# Helper function to generate and autoplay audio
def autoplay_audio(audio_bytes: bytes, hidden: bool = False):
    """
    Generates an HTML audio player that autoplays.
    If hidden, the player controls are not shown.
    """
    b64 = base64.b64encode(audio_bytes).decode()

    # Determine style for visibility
    style = "display:none;" if hidden else "width:100%;"

    audio_html = f"""
        <audio controls autoplay style="{style}">
          <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
          Your browser does not support the audio element.
        </audio>
        """
    st.components.v1.html(audio_html, height=None if hidden else 50)

def main():
    st.set_page_config(
        page_title="‡≤ö‡≤ø‡≤§‡≥ç‡≤∞‡≤µ‡≤æ‡≤ö‡≤ï (Chitravachaka)",
        page_icon="üìñ", 
        layout="centered",
        initial_sidebar_state="collapsed" # Collapse sidebar for this persona
    )

    # Custom CSS for a high-contrast, simple UI and a huge camera button
    st.markdown(
        """
        <style>
            body {
                background-color: #000000;
                color: #ffffff;
            }
            .main {
                background-color: #000000;
            }
            h1, h4 {
                color: #FFFF00; /* Bright yellow for high contrast */
                text-align: center;
            }
            /* Make the camera input button huge and unmissable */
            div[data-testid="stCameraInput"] button {
                background-color: #FFFF00;
                color: black;
                font-size: 24px;
                font-weight: bold;
                padding: 25px;
                border-radius: 15px;
                border: 3px solid white;
                display: block;
                margin: 20px auto;
                width: 90%;
                height: 120px;
            }
            /* Hide the "Drag and drop file" text */
            div[data-testid="stCameraInput"] small {
                display: none;
            }
        </style>
        """,
        unsafe_allow_html=True
    )

    st.markdown("<h1>‡≤ö‡≤ø‡≤§‡≥ç‡≤∞‡≤µ‡≤æ‡≤ö‡≤ï</h1>", unsafe_allow_html=True)

    # --- State Management and Audio Announcements ---

    # 1. Welcome message on first load
    if 'welcome_played' not in st.session_state:
        welcome_text = "‡≤ö‡≤ø‡≤§‡≥ç‡≤∞‡≤µ‡≤æ‡≤ö‡≤ï ‡≤Ö‡≤™‡≥ç‡≤≤‡≤ø‡≤ï‡≥á‡≤∂‡≤®‡≥ç‚Äå‡≤ó‡≥Ü ‡≤∏‡≥ç‡≤µ‡≤æ‡≤ó‡≤§. ‡≤ö‡≤ø‡≤§‡≥ç‡≤∞‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≥Ü‡≤∞‡≥Ü‡≤π‡≤ø‡≤°‡≤ø‡≤Ø‡≤≤‡≥Å ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤ï‡≥Ü‡≤≥‡≤ó‡≤ø‡≤® ‡≤¶‡≥ä‡≤°‡≥ç‡≤° ‡≤ï‡≥ç‡≤Ø‡≤æ‡≤Æ‡≥Ü‡≤∞‡≤æ ‡≤¨‡≤ü‡≤®‡≥ç ‡≤í‡≤§‡≥ç‡≤§‡≤ø‡≤∞‡≤ø."
        try:
            audio_bytes = text_to_speech(welcome_text, lang='kn')
            autoplay_audio(audio_bytes, hidden=True)
        except Exception as e:
            st.warning(f"Could not play welcome message: {e}")
        st.session_state.welcome_played = True

    # --- Main UI: The Camera Button ---
    
    # The camera input is the main interaction point.
    captured_image = st.camera_input(
        "‡≤ï‡≥ç‡≤Ø‡≤æ‡≤Æ‡≥Ü‡≤∞‡≤æ ‡≤¨‡≤ü‡≤®‡≥ç (Camera Button)", 
        key="camera_input"
    )

    # --- Processing Logic ---

    # Process the image only if a new one is captured
    if captured_image is not None and captured_image != st.session_state.get('last_image_processed'):
        st.session_state.last_image_processed = captured_image

        # 2. Announce image capture and processing
        processing_text = "‡≤ö‡≤ø‡≤§‡≥ç‡≤∞‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≥Ü‡≤∞‡≥Ü‡≤π‡≤ø‡≤°‡≤ø‡≤Ø‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü, ‡≤à‡≤ó ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥Ü."
        try:
            audio_bytes = text_to_speech(processing_text, lang='kn')
            autoplay_audio(audio_bytes, hidden=True)
        except Exception as e:
            st.warning(f"Could not play processing message: {e}")

        with st.spinner("üîÑ ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥Ü... (Processing...)"):
            try:
                image = Image.open(captured_image)
                if image.mode != 'RGB':
                    image = image.convert('RGB')
                image_np = np.array(image)

                # Extract text
                extracted_text = extract_text(image_np)

                if not extracted_text or not extracted_text.strip():
                    # 3a. Announce if no text is found
                    no_text_message = "‡≤ï‡≥ç‡≤∑‡≤Æ‡≤ø‡≤∏‡≤ø, ‡≤ö‡≤ø‡≤§‡≥ç‡≤∞‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤™‡≤†‡≥ç‡≤Ø ‡≤ï‡≤Ç‡≤°‡≥Å‡≤¨‡≤Ç‡≤¶‡≤ø‡≤≤‡≥ç‡≤≤. ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Ü ‡≤™‡≥ç‡≤∞‡≤Ø‡≤§‡≥ç‡≤®‡≤ø‡≤∏‡≤ø."
                    st.warning("‚ö†Ô∏è " + no_text_message)
                    audio_bytes = text_to_speech(no_text_message, lang='kn')
                    autoplay_audio(audio_bytes, hidden=True)
                else:
                    # 3b. Announce and read the extracted text
                    st.success("‚úÖ ‡≤™‡≤†‡≥ç‡≤Ø‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤Ø‡≤∂‡≤∏‡≥ç‡≤µ‡≤ø‡≤Ø‡≤æ‡≤ó‡≤ø ‡≤ì‡≤¶‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü! (Text read successfully!)")
                    
                    # Combine announcement and result for seamless playback
                    result_announcement = f"‡≤™‡≤†‡≥ç‡≤Ø‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤ó‡≥Å‡≤∞‡≥Å‡≤§‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü. {extracted_text}"
                    audio_bytes = text_to_speech(result_announcement, lang='kn')
                    
                    # Display the player with controls and autoplay
                    st.markdown("### üîä ‡≤´‡≤≤‡≤ø‡≤§‡≤æ‡≤Ç‡≤∂‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤Ü‡≤≤‡≤ø‡≤∏‡≤ø (Listen to the Result)")
                    autoplay_audio(audio_bytes, hidden=False)

                    # Provide a download button for the audio
                    st.download_button(
                        label="üì• ‡≤Ü‡≤°‡≤ø‡≤Ø‡≥ã ‡≤°‡≥å‡≤®‡≥ç‚Äå‡≤≤‡≥ã‡≤°‡≥ç ‡≤Æ‡≤æ‡≤°‡≤ø (Download Audio)",
                        data=audio_bytes,
                        file_name="kannada_speech.mp3",
                        mime="audio/mpeg"
                    )
                    # For sighted users, also display the text
                    st.info(f"**‡≤ó‡≥Å‡≤∞‡≥Å‡≤§‡≤ø‡≤∏‡≤≤‡≤æ‡≤¶ ‡≤™‡≤†‡≥ç‡≤Ø (Recognized Text):**\n\n{extracted_text}")

            except Exception as e:
                error_message = f"‡≤í‡≤Ç‡≤¶‡≥Å ‡≤¶‡≥ã‡≤∑ ‡≤∏‡≤Ç‡≤≠‡≤µ‡≤ø‡≤∏‡≤ø‡≤¶‡≥Ü: {str(e)}"
                st.error(error_message)
                audio_bytes = text_to_speech("‡≤ï‡≥ç‡≤∑‡≤Æ‡≤ø‡≤∏‡≤ø, ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≥Å‡≤µ‡≤æ‡≤ó ‡≤¶‡≥ã‡≤∑ ‡≤ï‡≤Ç‡≤°‡≥Å‡≤¨‡≤Ç‡≤¶‡≤ø‡≤¶‡≥Ü.", lang='kn')
                autoplay_audio(audio_bytes, hidden=True)

if __name__ == "__main__":
    # This is a workaround for a Streamlit issue where it might re-run the script
    # unnecessarily when new files are created. This disables the file watcher.
    if "server.fileWatcherType" not in st._config.get_options_for_section("server"):
        st._config.set_option("server.fileWatcherType", "none")
    main()
    
